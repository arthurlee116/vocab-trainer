{
  "experiment": {
    "name": "gemini25_flat",
    "model": "google/gemini-2.5-pro",
    "temperature": 0.05,
    "promptKey": "bilingualFlat"
  },
  "promptStyle": {
    "system": "Act as a bilingual vocabulary transcriber. Capture the heading each term belongs to.",
    "user": "Parse the entire worksheet. Return JSON with一个扁平 words[] 数组，包含 index、heading、text 字段。",
    "responseFormat": {
      "type": "json_schema",
      "json_schema": {
        "name": "flat_list_payload",
        "schema": {
          "type": "object",
          "properties": {
            "words": {
              "type": "array",
              "items": {
                "type": "object",
                "properties": {
                  "index": {
                    "type": "integer"
                  },
                  "text": {
                    "type": "string"
                  },
                  "heading": {
                    "type": "string"
                  }
                },
                "required": [
                  "text"
                ]
              }
            }
          },
          "required": [
            "words"
          ],
          "additionalProperties": false
        }
      }
    }
  },
  "result": {
    "id": "gen-1762565965-FjRF3Z5nSagk5Z2Lxhmk",
    "provider": "Google",
    "model": "google/gemini-2.5-pro",
    "object": "chat.completion",
    "created": 1762565976,
    "choices": [
      {
        "logprobs": null,
        "finish_reason": "stop",
        "native_finish_reason": "STOP",
        "index": 0,
        "message": {
          "role": "assistant",
          "content": "{\n  \"words\": [\n    {\n      \"text\": \"anthropology:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 1\n    },\n    {\n      \"text\": \"philosophy:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 2\n    },\n    {\n      \"text\": \"misanthrope:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 3\n    },\n    {\n      \"text\": \"hold sb. accountable for:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 4\n    },\n    {\n      \"text\": \"outlier\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 5\n    },\n    {\n      \"text\": \"stunting:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 6\n    },\n    {\n      \"text\": \"malnourished:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 7\n    },\n    {\n      \"text\": \"phenomenally:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 8\n    },\n    {\n      \"text\": \"hangs in the balance:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 9\n    },\n    {\n      \"text\": \"balance the books:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 10\n    },\n    {\n      \"text\": \"check and balance:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 11\n    },\n    {\n      \"text\": \"balance out:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 12\n    },\n    {\n      \"text\": \"throw off balance:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 13\n    },\n    {\n      \"text\": \"magic wand:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 14\n    },\n    {\n      \"text\": \"gut microbiome:\",\n      \"heading\": \"Goalkeeper\",\n      \"index\": 15\n    },\n    {\n      \"text\": \"hovel:\",\n      \"heading\": \"Hassan\",\n      \"index\": 1\n    },\n    {\n      \"text\": \"dank:\",\n      \"heading\": \"Hassan\",\n      \"index\": 2\n    },\n    {\n      \"text\": \"covet:\",\n      \"heading\": \"Hassan\",\n      \"index\": 3\n    },\n    {\n      \"text\": \"crave:\",\n      \"heading\": \"Hassan\",\n      \"index\": 4\n    },\n    {\n      \"text\": \"spool:\",\n      \"heading\": \"Hassan\",\n      \"index\": 5\n    },\n    {\n      \"text\": \"horde:\",\n      \"heading\": \"Hassan\",\n      \"index\": 6\n    },\n    {\n      \"text\": \"shove:\",\n      \"heading\": \"Hassan\",\n      \"index\": 7\n    },\n    {\n      \"text\": \"trophy:\",\n      \"heading\": \"Hassan\",\n      \"index\": 8\n    },\n    {\n      \"text\": \"uncoil:\",\n      \"heading\": \"Hassan\",\n      \"index\": 9\n    },\n    {\n      \"text\": \"coil:\",\n      \"heading\": \"Hassan\",\n      \"index\": 10\n    },\n    {\n      \"text\": \"overcast:\",\n      \"heading\": \"Hassan\",\n      \"index\": 11\n    },\n    {\n      \"text\": \"ragged:\",\n      \"heading\": \"Hassan\",\n      \"index\": 12\n    },\n    {\n      \"text\": \"plummet:\",\n      \"heading\": \"Hassan\",\n      \"index\": 13\n    },\n    {\n      \"text\": \"a cat has nine lives\",\n      \"heading\": \"14 Steps\",\n      \"index\": 1\n    },\n    {\n      \"text\": \"be the cat's whiskers\",\n      \"heading\": \"14 Steps\",\n      \"index\": 2\n    },\n    {\n      \"text\": \"let the cat out of the bag\",\n      \"heading\": \"14 Steps\",\n      \"index\": 3\n    },\n    {\n      \"text\": \"put the cat among the pigeons\",\n      \"heading\": \"14 Steps\",\n      \"index\": 4\n    },\n    {\n      \"text\": \"be inclined to\",\n      \"heading\": \"14 Steps\",\n      \"index\": 5\n    },\n    {\n      \"text\": \"inclination (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 6\n    },\n    {\n      \"text\": \"afflict (v.):\",\n      \"heading\": \"14 Steps\",\n      \"index\": 7\n    },\n    {\n      \"text\": \"affliction(s) (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 8\n    },\n    {\n      \"text\": \"afflictive (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 9\n    },\n    {\n      \"text\": \"be afflicted with/by\",\n      \"heading\": \"14 Steps\",\n      \"index\": 10\n    },\n    {\n      \"text\": \"progressive (adj.):\",\n      \"heading\": \"14 Steps\",\n      \"index\": 11\n    },\n    {\n      \"text\": \"with the aid of\",\n      \"heading\": \"14 Steps\",\n      \"index\": 12\n    },\n    {\n      \"text\": \"to a degree:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 13\n    },\n    {\n      \"text\": \"disillusioned (adj.):\",\n      \"heading\": \"14 Steps\",\n      \"index\": 14\n    },\n    {\n      \"text\": \"disillusionment (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 15\n    },\n    {\n      \"text\": \"hold on to:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 16\n    },\n    {\n      \"text\": \"lead up to:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 17\n    },\n    {\n      \"text\": \"sanity: (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 18\n    },\n    {\n      \"text\": \"slashing (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 19\n    },\n    {\n      \"text\": \"swerve (v.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 20\n    },\n    {\n      \"text\": \"dreaded (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 21\n    },\n    {\n      \"text\": \"enormity (n.):\",\n      \"heading\": \"14 Steps\",\n      \"index\": 22\n    },\n    {\n      \"text\": \"enormous (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 23\n    },\n    {\n      \"text\": \"peer at\",\n      \"heading\": \"14 Steps\",\n      \"index\": 24\n    },\n    {\n      \"text\": \"jack\",\n      \"heading\": \"14 Steps\",\n      \"index\": 25\n    },\n    {\n      \"text\": \"jack up:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 26\n    },\n    {\n      \"text\": \"frail (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 27\n    },\n    {\n      \"text\": \"frailty (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 28\n    },\n    {\n      \"text\": \"be all set:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 29\n    },\n    {\n      \"text\": \"penetrate(v.) penetration (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 30\n    },\n    {\n      \"text\": \"penetrating look (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 31\n    },\n    {\n      \"text\": \"fumble (v.):\",\n      \"heading\": \"14 Steps\",\n      \"index\": 32\n    },\n    {\n      \"text\": \"fumble with/in sth. for sth.\",\n      \"heading\": \"14 Steps\",\n      \"index\": 33\n    },\n    {\n      \"text\": \"be filled to overflowing with:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 34\n    },\n    {\n      \"text\": \"indifference (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 35\n    },\n    {\n      \"text\": \"indifferent (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 36\n    },\n    {\n      \"text\": \"scriptural (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 37\n    },\n    {\n      \"text\": \"admonition (n.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 38\n    },\n    {\n      \"text\": \"admonitory (adj.)\",\n      \"heading\": \"14 Steps\",\n      \"index\": 39\n    },\n    {\n      \"text\": \"beat down:\",\n      \"heading\": \"14 Steps\",\n      \"index\": 40\n    },\n    {\n      \"text\": \"adhere\",\n      \"heading\": \"Unit 13\",\n      \"index\": 1\n    },\n    {\n      \"text\": \"affirm\",\n      \"heading\": \"Unit 13\",\n      \"index\": 2\n    },\n    {\n      \"text\": \"atrocity\",\n      \"heading\": \"Unit 13\",\n      \"index\": 3\n    },\n    {\n      \"text\": \"cope\",\n      \"heading\": \"Unit 13\",\n      \"index\": 4\n    },\n    {\n      \"text\": \"deter\",\n      \"heading\": \"Unit 13\",\n      \"index\": 5\n    },\n    {\n      \"text\": \"disquieting\",\n      \"heading\": \"Unit 13\",\n      \"index\": 6\n    },\n    {\n      \"text\": \"empower\",\n      \"heading\": \"Unit 13\",\n      \"index\": 7\n    },\n    {\n      \"text\": \"fluent\",\n      \"heading\": \"Unit 13\",\n      \"index\": 8\n    },\n    {\n      \"text\": \"lag\",\n      \"heading\": \"Unit 13\",\n      \"index\": 9\n    },\n    {\n      \"text\": \"mangle\",\n      \"heading\": \"Unit 13\",\n      \"index\": 10\n    },\n    {\n      \"text\": \"misapprehension\",\n      \"heading\": \"Unit 13\",\n      \"index\": 11\n    },\n    {\n      \"text\": \"optimist\",\n      \"heading\": \"Unit 13\",\n      \"index\": 12\n    },\n    {\n      \"text\": \"prowl\",\n      \"heading\": \"Unit 13\",\n      \"index\": 13\n    },\n    {\n      \"text\": \"recitation\",\n      \"heading\": \"Unit 13\",\n      \"index\": 14\n    },\n    {\n      \"text\": \"stupefy\",\n      \"heading\": \"Unit 13\",\n      \"index\": 15\n    },\n    {\n      \"text\": \"sulky\",\n      \"heading\": \"Unit 13\",\n      \"index\": 16\n    },\n    {\n      \"text\": \"supplement\",\n      \"heading\": \"Unit 13\",\n      \"index\": 17\n    },\n    {\n      \"text\": \"surge\",\n      \"heading\": \"Unit 13\",\n      \"index\": 18\n    },\n    {\n      \"text\": \"trait\",\n      \"heading\": \"Unit 13\",\n      \"index\": 19\n    },\n    {\n      \"text\": \"unscrupulous.\",\n      \"heading\": \"Unit 13\",\n      \"index\": 20\n    },\n    {\n      \"text\": \"abstain\",\n      \"heading\": \"Unit 14\",\n      \"index\": 1\n    },\n    {\n      \"text\": \"accommodate\",\n      \"heading\": \"Unit 14\",\n      \"index\": 2\n    },\n    {\n      \"text\": \"allegiance\",\n      \"heading\": \"Unit 14\",\n      \"index\": 3\n    },\n    {\n      \"text\": \"amalgamate\",\n      \"heading\": \"Unit 14\",\n      \"index\": 4\n    },\n    {\n      \"text\": \"append\",\n      \"heading\": \"Unit 14\",\n      \"index\": 5\n    },\n    {\n      \"text\": \"commemorate\",\n      \"heading\": \"Unit 14\",\n      \"index\": 6\n    },\n    {\n      \"text\": \"enumerate\",\n      \"heading\": \"Unit 14\",\n      \"index\": 7\n    },\n    {\n      \"text\": \"exalt\",\n      \"heading\": \"Unit 14\",\n      \"index\": 8\n    },\n    {\n      \"text\": \"far-fetched\",\n      \"heading\": \"Unit 14\",\n      \"index\": 9\n    },\n    {\n      \"text\": \"extort\",\n      \"heading\": \"Unit 14\",\n      \"index\": 10\n    },\n    {\n      \"text\": \"glum\",\n      \"heading\": \"Unit 14\",\n      \"index\": 11\n    },\n    {\n      \"text\": \"replica\",\n      \"heading\": \"Unit 14\",\n      \"index\": 12\n    },\n    {\n      \"text\": \"responsive\",\n      \"heading\": \"Unit 14\",\n      \"index\": 13\n    },\n    {\n      \"text\": \"sanctuary\",\n      \"heading\": \"Unit 14\",\n      \"index\": 14\n    },\n    {\n      \"text\": \"self-seeking\",\n      \"heading\": \"Unit 14\",\n      \"index\": 15\n    },\n    {\n      \"text\": \"submissive\",\n      \"heading\": \"Unit 14\",\n      \"index\": 16\n    },\n    {\n      \"text\": \"tally\",\n      \"heading\": \"Unit 14\",\n      \"index\": 17\n    },\n    {\n      \"text\": \"taskmaster\",\n      \"heading\": \"Unit 14\",\n      \"index\": 18\n    },\n    {\n      \"text\": \"transform\",\n      \"heading\": \"Unit 14\",\n      \"index\": 19\n    },\n    {\n      \"text\": \"upheaval\",\n      \"heading\": \"Unit 14\",\n      \"index\": 20\n    },\n    {\n      \"text\": \"beacon\",\n      \"heading\": \"Unit 15\",\n      \"index\": 1\n    },\n    {\n      \"text\": \"berserk\",\n      \"heading\": \"Unit 15\",\n      \"index\": 2\n    },\n    {\n      \"text\": \"celestial\",\n      \"heading\": \"Unit 15\",\n      \"index\": 3\n    },\n    {\n      \"text\": \"chasten\",\n      \"heading\": \"Unit 15\",\n      \"index\": 4\n    },\n    {\n      \"text\": \"confiscate\",\n      \"heading\": \"Unit 15\",\n      \"index\": 5\n    },\n    {\n      \"text\": \"data\",\n      \"heading\": \"Unit 15\",\n      \"index\": 6\n    },\n    {\n      \"text\": \"detract\",\n      \"heading\": \"Unit 15\",\n      \"index\": 7\n    },\n    {\n      \"text\": \"encounter\",\n      \"heading\": \"Unit 15\",\n      \"index\": 8\n    },\n    {\n      \"text\": \"epic\",\n      \"heading\": \"Unit 15\",\n      \"index\": 9\n    },\n    {\n      \"text\": \"pantomime.\",\n      \"heading\": \"Unit 15\",\n      \"index\": 10\n    },\n    {\n      \"text\": \"pessimist\",\n      \"heading\": \"Unit 15\",\n      \"index\": 11\n    },\n    {\n      \"text\": \"precaution\",\n      \"heading\": \"Unit 15\",\n      \"index\": 12\n    },\n    {\n      \"text\": \"prosecute\",\n      \"heading\": \"Unit 15\",\n      \"index\": 13\n    },\n    {\n      \"text\": \"puncture\",\n      \"heading\": \"Unit 15\",\n      \"index\": 14\n    },\n    {\n      \"text\": \"retaliate\",\n      \"heading\": \"Unit 15\",\n      \"index\": 15\n    },\n    {\n      \"text\": \"sham\",\n      \"heading\": \"Unit 15\",\n      \"index\": 16\n    },\n    {\n      \"text\": \"uncouth\",\n      \"heading\": \"Unit 15\",\n      \"index\": 17\n    },\n    {\n      \"text\": \"underscore\",\n      \"heading\": \"Unit 15\",\n      \"index\": 18\n    },\n    {\n      \"text\": \"wholesome\",\n      \"heading\": \"Unit 15\",\n      \"index\": 19\n    },\n    {\n      \"text\": \"wistful\",\n      \"heading\": \"Unit 15\",\n      \"index\": 20\n    }\n  ]\n}",
          "refusal": null,
          "reasoning": "**Analyzing the Task's Requirements**\n\nI'm starting to formalize the specifics for this vocabulary transcription. The core is extracting text from an image and structuring it into JSON. Right now, I'm focusing on the JSON output format, particularly the `words` array. Indexing, headings, and texts are clear enough.\n\n\n**Mapping the Extraction Steps**\n\nI'm now detailing each step for the extraction process. First, I'll extract text. Then, I'll identify headings like \"Goalkeeper\" and \"Hassan\". Next comes parsing the words associated with each heading, and assigning the proper index to each word. After that, I will construct objects for each word, using the extracted data, and append each to the array. Finally, I'll ensure the final JSON object is valid and correctly formatted.\n\n\n**Decomposing the Provided Data**\n\nI'm now diving into the provided data, analyzing the structure and content. I see distinct headings and associated word lists, a crucial starting point for parsing. My primary focus is to map each word to its index and the appropriate heading to correctly populate the `words` array. I'll need to account for potential formatting inconsistencies within the data.\n\n\n**Generating the JSON Structure**\n\nI'm generating the JSON output structure, starting with the array of `words`. I've constructed objects for each word, accurately mapping its index, heading, and text. Now, I'm verifying the format to ensure a valid JSON string. I will incorporate this final data into the existing JSON template.\n\n\n**Creating the Word Objects**\n\nI'm now iterating through the provided word lists, creating objects for each word, containing its index, heading, and text. I'm focusing on ensuring accurate association and index assignment based on the headings. Once I've finished, I will put all objects in a single array.\n\n\n**Forming the Final Array**\n\nI'm now consolidating the word objects into a single `words` array, meticulously combining the elements from each heading's word list. I'm focusing on preserving the accurate sequence of elements. I'm putting it all together now.\n\n\n**Assembling the Word Objects**\n\nI'm now generating all the word objects, correctly assigning each item to the proper section based on the headings. I've finished the \"Goalkeeper\", \"Hassan\", and \"14 Steps\" sections, and created word objects for all of them. I'm now moving on to the remaining sections, \"Unit 13\", \"Unit 14\", and \"Unit 15\".\n\n\n**Formulating the Output Data**\n\nI'm now creating the JSON output based on the structured data. I'm taking all the individual word objects and merging them into the final `words` array. Then, I need to enclose the array in a parent JSON object.\n\n\n**Compiling the Data**\n\nI'm now collating the lists of words under each heading, preparing to create the final JSON output. The data is parsed, indexed, and organized. I'm focusing on preserving the order within each section, and assembling the word objects.\n\n\n**Constructing the Output**\n\nI'm now generating the final JSON output, putting the `words` array together, based on the objects I have created for each word in each section. I'm focusing on preserving both the overall structure and the integrity of the data.\n\n\n**Refining Data Formatting**\n\nI'm now carefully inspecting the extracted data, checking index assignments and object formatting. I'm focusing on \"Unit 15\" currently, and confirming text accuracy. Now, I'm verifying the formatting of the JSON output and working on the final JSON array.\n\n\n**Creating the Final Output**\n\nI'm now putting everything together. I've created all the word objects with their `index`, `heading`, and `text`. I'm merging all word objects into a single array and formatting the final JSON, making sure the order is correct. I am ready to generate the JSON now.\n\n\n**Constructing the Output JSON**\n\nI'm now in the final stage, merging all generated word objects into a single `words` array. This step involves merging the contents of the individual objects. I'm focusing on ensuring data integrity. I'll make sure the format of the output is compliant.\n\n\n",
          "reasoning_details": [
            {
              "type": "reasoning.text",
              "text": "**Analyzing the Task's Requirements**\n\nI'm starting to formalize the specifics for this vocabulary transcription. The core is extracting text from an image and structuring it into JSON. Right now, I'm focusing on the JSON output format, particularly the `words` array. Indexing, headings, and texts are clear enough.\n\n\n**Mapping the Extraction Steps**\n\nI'm now detailing each step for the extraction process. First, I'll extract text. Then, I'll identify headings like \"Goalkeeper\" and \"Hassan\". Next comes parsing the words associated with each heading, and assigning the proper index to each word. After that, I will construct objects for each word, using the extracted data, and append each to the array. Finally, I'll ensure the final JSON object is valid and correctly formatted.\n\n\n**Decomposing the Provided Data**\n\nI'm now diving into the provided data, analyzing the structure and content. I see distinct headings and associated word lists, a crucial starting point for parsing. My primary focus is to map each word to its index and the appropriate heading to correctly populate the `words` array. I'll need to account for potential formatting inconsistencies within the data.\n\n\n**Generating the JSON Structure**\n\nI'm generating the JSON output structure, starting with the array of `words`. I've constructed objects for each word, accurately mapping its index, heading, and text. Now, I'm verifying the format to ensure a valid JSON string. I will incorporate this final data into the existing JSON template.\n\n\n**Creating the Word Objects**\n\nI'm now iterating through the provided word lists, creating objects for each word, containing its index, heading, and text. I'm focusing on ensuring accurate association and index assignment based on the headings. Once I've finished, I will put all objects in a single array.\n\n\n**Forming the Final Array**\n\nI'm now consolidating the word objects into a single `words` array, meticulously combining the elements from each heading's word list. I'm focusing on preserving the accurate sequence of elements. I'm putting it all together now.\n\n\n**Assembling the Word Objects**\n\nI'm now generating all the word objects, correctly assigning each item to the proper section based on the headings. I've finished the \"Goalkeeper\", \"Hassan\", and \"14 Steps\" sections, and created word objects for all of them. I'm now moving on to the remaining sections, \"Unit 13\", \"Unit 14\", and \"Unit 15\".\n\n\n**Formulating the Output Data**\n\nI'm now creating the JSON output based on the structured data. I'm taking all the individual word objects and merging them into the final `words` array. Then, I need to enclose the array in a parent JSON object.\n\n\n**Compiling the Data**\n\nI'm now collating the lists of words under each heading, preparing to create the final JSON output. The data is parsed, indexed, and organized. I'm focusing on preserving the order within each section, and assembling the word objects.\n\n\n**Constructing the Output**\n\nI'm now generating the final JSON output, putting the `words` array together, based on the objects I have created for each word in each section. I'm focusing on preserving both the overall structure and the integrity of the data.\n\n\n**Refining Data Formatting**\n\nI'm now carefully inspecting the extracted data, checking index assignments and object formatting. I'm focusing on \"Unit 15\" currently, and confirming text accuracy. Now, I'm verifying the formatting of the JSON output and working on the final JSON array.\n\n\n**Creating the Final Output**\n\nI'm now putting everything together. I've created all the word objects with their `index`, `heading`, and `text`. I'm merging all word objects into a single array and formatting the final JSON, making sure the order is correct. I am ready to generate the JSON now.\n\n\n**Constructing the Output JSON**\n\nI'm now in the final stage, merging all generated word objects into a single `words` array. This step involves merging the contents of the individual objects. I'm focusing on ensuring data integrity. I'll make sure the format of the output is compliant.\n\n\n",
              "format": "unknown",
              "index": 0
            }
          ]
        }
      }
    ],
    "usage": {
      "prompt_tokens": 1847,
      "completion_tokens": 9236,
      "total_tokens": 11083,
      "prompt_tokens_details": {
        "cached_tokens": 1258
      },
      "completion_tokens_details": {
        "reasoning_tokens": 4919,
        "image_tokens": 0
      }
    }
  }
}